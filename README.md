Image Caption Generator with Attention Module   
In this project the Model has been developed on the framework of the state of the art RESNET50 V2/ EfficientNetB4 and GRU with an Attentionn Module to Generate the caption for the Images autonomously. The RESNETV2 was used for feature extraction from the Images and the extracted feature were later fed to the RNN using GRU to develop as seq2seq model. this model alone was not producing the best resullts, so we decided to integrate the attention module for optimized performance. the attention module used for this purpose was a soft attention module developed by bahdanau. This model was trained on the datasets such as Flickr8K and Flickr30K using the ADAm optimizer for performance evaluation. the Loss was calculated by using the Sparse Categorical Cross entropy. 